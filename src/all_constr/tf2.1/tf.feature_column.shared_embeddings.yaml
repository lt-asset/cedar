constraints:
  categorical_columns:
    descp: List of categorical columns created by a`categorical_column_with_*` function.
      These columns produce the sparse IDs that are inputs to the embedding lookup.
      All columns must be of the same type and have the same arguments except `key`.
      E.g. they can be categorical_column_with_vocabulary_file with the same vocabulary_file.
      Some or all columns could also be weighted_categorical_column.
    structure:
    - list
  ckpt_to_load_from:
    default: None
    descp: String representing checkpoint name/pattern from which to restore column
      weights. Required if `tensor_name_in_ckpt` is not `None`.
  combiner:
    default: mean
    descp: A string specifying how to reduce if there are multiple entries in a single
      row. Currently 'mean', 'sqrtn' and 'sum' are supported, with 'mean' the default.
      'sqrtn' often achieves good accuracy, in particular with bag-of-words columns.
      Each of this can be thought as example level normalizations on the column. For
      more information, see`tf.embedding_lookup_sparse`.
    dtype:
    - tf.string
    enum:
    - mean
    - sqrtn
    - sum
    ndim:
    - '0'
  dimension:
    descp: An integer specifying dimension of the embedding, must be > 0.
  initializer:
    default: None
    descp: A variable initializer function to be used in embedding variable initialization.
      If not specified, defaults to`truncated_normal_initializer` with mean `0.0`
      and standard deviation `1/sqrt(dimension)`.
    ndim:
    - '0'
  max_norm:
    default: None
    descp: If not `None`, each embedding is clipped if its l2-norm is larger than
      this value, before combining.
  shared_embedding_collection_name:
    default: None
    descp: Optional collective name of these columns. If not given, a reasonable name
      will be chosen based on the names of`categorical_columns`.
    dtype:
    - tf.string
    ndim:
    - '0'
  tensor_name_in_ckpt:
    default: None
    descp: Name of the `Tensor` in `ckpt_to_load_from` from which to restore the column
      weights. Required if `ckpt_to_load_from` is not `None`.
    dtype:
    - tf.string
    ndim:
    - '0'
    tensor_t:
    - tf.tensor
  trainable:
    default: 'True'
    descp: Whether or not the embedding is trainable. Default is True.
    dtype:
    - tf.bool
    ndim:
    - '0'
exceptions:
- ValueError: if `dimension` not > 0.
- ValueError: if any of the given `categorical_columns` is of different type or has
    different arguments than the others.
- ValueError: if exactly one of `ckpt_to_load_from` and `tensor_name_in_ckpt`is specified.
- ValueError: if `initializer` is specified and is not callable.
- RuntimeError: if eager execution is enabled.
inputs:
  optional:
  - combiner
  - initializer
  - shared_embedding_collection_name
  - ckpt_to_load_from
  - tensor_name_in_ckpt
  - max_norm
  - trainable
  required:
  - categorical_columns
  - dimension
link: https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/feature_column/shared_embeddings
outputs: A list of dense columns that converts from sparse input. The order of results
  follows the ordering of `categorical_columns`.
package: tensorflow
target: shared_embeddings
title: tf.feature_column.shared_embeddings
version: 2.1.0
