aliases:
- tf.compat.v1.data.experimental.dense_to_ragged_batch
constraints:
  batch_size:
    descp: A `tf.int64` scalar `tf.Tensor`, representing the number of consecutive
      elements of this dataset to combine in a single batch.
    dtype:
    - tf.int64
    ndim:
    - '0'
    range:
    - '[0,inf)'
    tensor_t:
    - tf.tensor
  drop_remainder:
    default: 'False'
    descp: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing whether the last
      batch should be dropped in the case it has fewer than`batch_size` elements;
      the default behavior is not to drop the smaller batch.
    dtype:
    - tf.bool
    ndim:
    - '0'
  row_splits_dtype:
    default: tf.dtypes.int64
    descp: The dtype that should be used for the `row_splits` of any new ragged tensors.  Existing
      `tf.RaggedTensor` elements do not have their row_splits dtype changed.
    dtype:
    - tf.dtype
    - tf.int64
inputs:
  optional:
  - drop_remainder
  - row_splits_dtype
  required:
  - batch_size
link: https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/data/experimental/dense_to_ragged_batch
outputs:
- Dataset: A `Dataset`.
package: tensorflow
target: dense_to_ragged_batch
title: tf.data.experimental.dense_to_ragged_batch
version: 2.1.0
