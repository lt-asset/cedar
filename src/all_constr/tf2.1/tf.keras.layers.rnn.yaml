aliases:
- tf.compat.v1.keras.layers.RNN
check_nan: true
constraints:
  '**kwargs':
    default: null
    descp: ''
  cell:
    descp: 'A RNN cell instance or a list of RNN cell instances. A RNN cell is a class
      that has: A `call(input_at_t, states_at_t)` method, returning`(output_at_t,
      states_at_t_plus_1)`. The call method of the cell can also take the optional
      argument `constants`, see section "Note on passing external constants" below.A
      `state_size` attribute. This can be a single integer (single state) in which
      case it is the size of the recurrent state. This can also be a list/tuple of
      integers (one size per state). The `state_size` can also be TensorShape or tuple/list
      of TensorShape, to represent high dimension state.A `output_size` attribute.
      This can be a single integer or a TensorShape, which represent the shape of
      the output. For backward compatible reason, if this attribute is not available
      for the cell, the value will be inferred by the first element of the`state_size`.A
      `get_initial_state(inputs=None, batch_size=None, dtype=None)`method that creates
      a tensor meant to be fed to `call()` as the initial state, if the user didn''t
      specify any initial state via other means. The returned initial state should
      have a shape of [batch_size, cell.state_size]. The cell might choose to create
      a tensor full of zeros, or full of other values based on the cell''s implementation.`inputs`
      is the input tensor to the RNN layer, which should contain the batch size as
      its shape[0], and also dtype. Note that the shape[0] might be `None` during
      the graph construction. Either the `inputs` or the pair of `batch_size` and
      `dtype` are provided.`batch_size` is a scalar tensor that represents the batch
      size of the inputs. `dtype` is `tf.DType` that represents the dtype of the inputs.
      For backward compatible reason, if this method is not implemented by the cell,
      the RNN layer will create a zero filled tensor with the size of [batch_size,
      cell.state_size]. In the case that `cell` is a list of RNN cell instances, the
      cells will be stacked on top of each other in the RNN, resulting in an efficient
      stacked RNN. '
    dtype:
    - int
    - tf.dtype
    - tf.string
    enum:
    - batch_size
    - dtype
    - inputs
    ndim:
    - '0'
    - '1'
    structure:
    - list
    - tuple
    tensor_t:
    - tf.tensor
  go_backwards:
    default: 'False'
    descp: Boolean (default `False`). If True, process the input sequence backwards
      and return the reversed sequence.
    dtype:
    - tf.bool
    ndim:
    - '0'
    structure:
    - list
  return_sequences:
    default: 'False'
    descp: Boolean (default `False`). Whether to return the last output in the output
      sequence, or the full sequence.
    dtype:
    - tf.bool
    ndim:
    - '0'
  return_state:
    default: 'False'
    descp: Boolean (default `False`). Whether to return the last state in addition
      to the output.
    dtype:
    - tf.bool
    ndim:
    - '0'
  stateful:
    default: 'False'
    descp: Boolean (default `False`). If True, the last state for each sample at index
      i in a batch will be used as initial state for the sample of index i in the
      following batch.
    dtype:
    - tf.bool
    ndim:
    - '0'
  time_major:
    default: 'False'
    descp: The shape format of the `inputs` and `outputs` tensors. If True, the inputs
      and outputs will be in shape`(timesteps, batch, ...)`, whereas in the False
      case, it will be`(batch, timesteps, ...)`. Using `time_major = True` is a bit
      more efficient because it avoids transposes at the beginning and end of the
      RNN calculation. However, most TensorFlow data is batch-major, so by default
      this function accepts input and emits output in batch-major form.
    dtype:
    - tf.bool
    ndim:
    - '0'
    tensor_t:
    - tf.tensor
  unroll:
    default: 'False'
    descp: Boolean (default `False`). If True, the network will be unrolled, else
      a symbolic loop will be used. Unrolling can speed-up a RNN, although it tends
      to be more memory-intensive. Unrolling is only suitable for short sequences.
    dtype:
    - tf.bool
    ndim:
    - '0'
exceptions:
- AttributeError: When the RNN layer is not stateful.
- ValueError: When the batch size of the RNN layer is unknown.
- ValueError: When the input numpy array is not compatible with the RNN layer state,
    either size wise or dtype wise.
inputs:
  optional:
  - return_sequences
  - return_state
  - go_backwards
  - stateful
  - unroll
  - time_major
  - '**kwargs'
  required:
  - cell
layer_constructor: true
link: https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/layers/RNN
package: tensorflow
target: RNN
title: tf.keras.layers.RNN
version: 2.1.0
