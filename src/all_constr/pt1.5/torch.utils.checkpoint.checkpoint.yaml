constraints:
  '**kwargs':
    descp: ''
  '*args':
    descp: tuple containing inputs to the `function`
    dtype:
    - torch.bool
    ndim:
    - '0'
    structure:
    - tuple
  function:
    descp: describes what to run in the forward pass of the model or part of the model.
      It should also know how to handle the inputs passed as the tuple. For example,
      in LSTM, if user passes `(activation, hidden)`, `function` should correctly
      use the first input as `activation` and the second input as `hidden`
    dtype:
    - torch.bool
    enum:
    - activation
    - function
    - hidden
    ndim:
    - '0'
    structure:
    - tuple
  preserve_rng_state:
    default: None
    descp: Omit stashing and restoring the RNG state during each checkpoint.
    doc_dtype: bool, optional, default=True
    dtype:
    - torch.bool
    ndim:
    - '0'
inputs:
  optional:
  - preserve_rng_state
  required:
  - function
  - '*args'
  - '**kwargs'
link: https://pytorch.org/docs/stable/checkpoint.html#torch.utils.checkpoint.checkpoint
package: torch
target: checkpoint
title: torch.utils.checkpoint.checkpoint
version: 1.5.0
