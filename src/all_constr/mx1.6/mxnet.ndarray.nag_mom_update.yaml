check_nan: true
constraints:
  '**kwargs':
    descp: ''
  clip_gradient:
    default: _Null
    descp: Clip gradient to the range of [-clip_gradient, clip_gradient] If clip_gradient
      <= 0, gradient clipping is turned off. grad = max(min(grad, clip_gradient),
      -clip_gradient).
    doc_dtype: float, optional, default=-1
    dtype:
    - float
    ndim:
    - '0'
  grad:
    default: None
    descp: Gradient
    doc_dtype: NDArray
    structure:
    - ndarray
  lr:
    default: _Null
    descp: Learning rate
    doc_dtype: float, required
    dtype:
    - float
  mom:
    default: None
    descp: Momentum
    doc_dtype: NDArray
    structure:
    - ndarray
  momentum:
    default: _Null
    descp: The decay rate of momentum estimates at each epoch.
    doc_dtype: float, optional, default=0
    dtype:
    - float
    ndim:
    - '0'
  name:
    default: None
    descp: ''
  out:
    default: None
    descp: The output NDArray to hold the result.
    doc_dtype: NDArray, optional
    structure:
    - ndarray
  rescale_grad:
    default: _Null
    descp: Rescale gradient to grad = rescale_grad*grad.
    doc_dtype: float, optional, default=1
    dtype:
    - float
    ndim:
    - '0'
  wd:
    default: _Null
    descp: Weight decay augments the objective function with a regularization term
      that penalizes large weights. The penalty scales with the square of the magnitude
      of each weight.
    doc_dtype: float, optional, default=0
    dtype:
    - float
    ndim:
    - '0'
  weight:
    default: None
    descp: Weight
    doc_dtype: NDArray
    structure:
    - ndarray
inputs:
  optional:
  - weight
  - grad
  - mom
  - lr
  - momentum
  - wd
  - rescale_grad
  - clip_gradient
  - out
  - name
  required:
  - '**kwargs'
link: https://mxnet.apache.org/versions/1.6/api/python/docs/api/ndarray/ndarray.html#mxnet.ndarray.nag_mom_update
package: mxnet
target: nag_mom_update
title: mxnet.ndarray.nag_mom_update
version: 1.6.0
